# -*- coding: utf-8 -*-
"""Proyecto_Final_Nabila_Valdez.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15N1dptxMfnoyyRsMWmjRroFGXM49L5tB

# **Cancer de Mama**

![cancer-de-mama.jpg](data:image/jpeg;base64,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)

# **Abstract**
El cáncer de mama es el tipo de cáncer más frecuente en mujeres, se origina cuando las celulas mamarias comienzan a crecer sin control, las celulas cancerosas normalmente forman un tumor.
Los factores de riesgo de contraer cancer de mama, incluye ser mujer, tener una edad avanzada, edad avanzada en el momento de tener un parto o nunca haber dado a luz, antecedentes familiares de cancer de mama o el hecho de consumir hormonas tales como el estrogeno o progesterona. En nuestro país, se estima que una de cada diez mujeres puede padecerlo en algún momento de su vida. Aunque una gran mayoría de los tumores de mama se acaban curando, aún hoy en día cerca de un 20% de las pacientes no lo superan. La resistencia a los tratamientos o la ausencia de terapias específicas contra determinados tipos de cáncer de mama son la principal causa de que ciertos tumores no se puedan eliminar completamente.
Es una enfermedad causada por la multiplicación anormal de las células de la mama que forman un tumor maligno. Puede afectar a cualquier mujer, las posibilidades de que aparezca aumentan con la edad, en especial a partir de los 50 años. El objetivo con este trabajo es mostar de acuerdo a los datos obtenidos que eL cancer de mamas puede llegar a ser un cancer engañoso, las mujeres debemos tener conciencia de los sintomas que pueden surgir de manera aislada o no, va a depender mucho de la persona, pero que si tiene que estar alerto a los dolores o molestias que puede llegar a sentir, ya que este cancer en su mayoria empieza sin ningun tipo de sintomas pero con algunas protuberancias y se puede ir incrementado a lo largo del tiempo. Nuestro proposito es que mujeres de todas las edades, desde su adolescencia por lo general, tengan conocimiento de esta enfermedad y se realicen los estudios pertinentes con su medico/a de confianza. Este dataset fue realizado este año alrededor de unas 285 mujeres de distintas partes de buenos aires, con edades que van desde los 30 a los 70 años de edad, dentro de el podremos ver algunas indicaciones de como se situan los sintomas del mismo cancer de mamas. En las columnas del pripio dataset veremos si tuvieron algun sintoma o no con respecto a la enfermedad, podemos ver la edad de ellas, si son mujeres con menopausia o no, si tienen algun nodulo en el o los pechos de acuerdo a su tamaño, tambien ver si es maligno ese nodulo o no, en que pecho se encuentra el nodulo, o tumor si es el caso que existiera, si estuvieron expuestas a alguna sesion de rayos o quimioterapia.
**Preguntas**
Podremos ver ¿A partir de que edad se incrementa el cancer de mamas, ¿Donde se hace mas notable la aparicion del cancer?, ¿Cual es la zona mas comun de su aparicion de acuerdo a los datos realizados?, De acuerdo con los datos establecios ¿La mayoria de estas mujeres recibieron algun tratamiento/medicacion por la enfermedad? y ¿Cuantas de ellas llegaron a tener tumores malignos?. ¿Porque?.
"""

import json
import os
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib as mpl
from googleapiclient.discovery import build
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from wordcloud import WordCloud

"""# Importamos el Dataset"""

Cancer= pd.read_csv("/content/drive/MyDrive/Descargas_Kaggle/Cancer_de_Mama/breast-cancer.csv")
Cancer.shape

Cancer.sample(5)

"""# Informacion del Dataset"""

#verificamos que tipo de valores arroja la columna objetivo
Cancer['Class'].unique()

#revisemos los tipo de datos de  nuestro dataset
Cancer.info()

#veamos algunas estadisticas
Cancer.describe()

Cancer.describe().T

Cancer.isnull().sum()

"""#Visualizacion Univariado
Mostramos cada columna/variable que encontramos dentro del dataset. Para ver lo que hay en la columna class a ultilizar una funcion de histograama pero de la libreria de seaborn.
"""

#Ahora veamos como se distribuyen nuestras muestras con el valor objetivo
dist = Cancer['Class'].value_counts()
sns.barplot(x = dist.index, y=dist)

"""En esta seccion podemos ver que dentro del dataset en la columna class se clasifica a las mujeres, que obtuvieron sus datos, por si tuvierion/tiene algun sintoma o no del cancer de mamas. Los separa por las que Si tuvieron y por las que No tuvieron ni presentaron ningun sintoma hasta entonces.

En la siguiente columna "Age" podemos encontrar la edad de las personas a las cuales tenemos sus datos mediante el dataset.
Para visualizar estos datos tambien haremos un histograma para saber dentro de que rango de edad estamos trabajando.
"""

dist = Cancer['Age'].value_counts()
sns.barplot(x = dist.index, y=dist)

"""Como podemos notar tenemos datos de mujeres a partir de los 20 años hasta los 70 aproximadamente. Si bien este dataset trabaja con estos datos no quiere decir que una mujer joven no pueda llegar a tener este tipo de cancer o empezar con algun sintoma no tan notorio.

Buscaremos informacion a ver que hace refencia la columna de "Menopause" dentro del dataset. Para eso tambien decidimos visualizarlo con un histograma de la libreria de seaborn
"""

dist = Cancer['Menopause'].value_counts()
sns.barplot(x = dist.index, y=dist)

"""Este grafico nos indica que existen tres tipos de clasificacion en la columna de "Menopause", las mujeres que no lo tienen, las que lo tienen o estan cursando ese periodo y por ultimo las que a pasaron esa etapa.

Viisualizaremos la columna "Tumor-size" para saber que tamaño de tumores podemos en encontrar dentro del dataset.  Para eso tambien decidimos visualizarlo con un histograma de la libreria de seaborn
"""

dist = Cancer['Tumor-size'].value_counts()
sns.barplot(x = dist.index, y=dist)

"""En base a este grafico podemos observar diviersos tipos de tamaños de los tumores que tienen estas mujeres en relacion a sus datos y puestos en milimetros, como podemos ver existe una catidad de mujeres que tienen entre 3 y 3,4cm del tumor, luego otra cantidad entre 2cm y 2,9cm del tamañoo del tumor.

En el siguiente grafico vamos a graficar la columna "Inv.nodes" con respeco a los datos descriptos dentro del dataset. Para eso tambien decidimos visualizarlo con un histograma de la libreria de seaborn
"""

dist = Cancer['Inv-nodes'].value_counts()
sns.barplot(x = dist.index, y=dist)

"""Lo que podemos ver en el grafico la cantidad de nodulos invasivos que tienen las mujeres, existe una ccantidad muy elevada de mujeres que no tiene este tipos de nodulos invasivos por ende no tienen el cancer avanzado

En este grafico vamos a visualizar la columna "Node-caps". Para eso tambien decidimos visualizarlo con un histograma de la libreria de seaborn
"""

dist = Cancer['Node-caps'].value_counts()
sns.barplot(x = dist.index, y=dist)

"""El grafico hace referencia si esos nodulos o celulas cencerosas que  forman alguna "bolita" en el seno, tambien si estas celulas viajaron por los vasos sangiuneos hasta llegar a los nodulos linfaticos. Los divide en Si, No.

Visualizamos la columna "Deg-malig" para este utilizamos un boxplot de la libreria de seaborn
"""

sns.boxplot(data= Cancer, x="Deg-malig")
plt.show()

"""Con este grafico podemos saber si hay grados malignos del cancer de mama con respectos a estos datos del dataset. Aca podemos ver que la gran mayoria de las mujeres que tienen un toomor maligno estan entre el grado 2 y 3 de la etapa avanzada.

En la columna "Breast" visualizaremos los datos de cual de las mamas aparece con frecuencia segun los datos del dataset. Para eso usamos el histograma con la libreria de seaborn
"""

dist = Cancer['Breast'].value_counts()
sns.barplot(x = dist.index, y=dist)

"""Segun estos datos el seno donde mas las mujeres tienen algun sintoma, protuberancia, o se origiina el cancer es en el seno izquierdo eso no nos asegura que sea siempre asi o inclusive pueden tener en ambos senos.

Mostraremos que datos se encuentra en la columna "Breast-quad" con la herramienta de histograama de la libreria seaborn.
"""

dist = Cancer['Breast-quad'].value_counts()
sns.barplot(x = dist.index, y=dist)

"""El grafico nos indiica en que parte de la zona del pecho aparece algun sintoma del cancer de mama por lo general en las mujeres dentro del dataset, nos idica que ellas sintieron en el lado izquiero hacia arriba.

Y por ulitma columna tenemoos a "Irradiat" donde usaremos un histograma con la libreria de seaborn
"""

dist = Cancer['Irradiat'].value_counts()
sns.barplot(x = dist.index, y=dist)

"""En esta columna podemos ver si las mujeres dentro del dataset tuvieron o recibierion algun tratamiento de la enfermedad o lo estan recibiendo como la radioterapia o quimioterapia.
En la mayotia de estas mujeres no tuvieron ni necesitaron recibir algun tratamiento de radioterapia

# **Visualizacion Bivariado**

Quisimos combinar los datos de la edad de la mujeres del dataset, con los datos de la columna "Class" para ver si hay una relacion con la edad y los sintomas del cancer de mamas. Atraves de un grafico de lineas
"""

sns.lineplot(data= Cancer, x= "Age", y= "Class")

"""En este grafico se puede ver una relacion ascendente de la edad con respecto a los sintomas del cancer de mama, podemos ver que por lo general las mujeres a partir de los 30 años en adelante empiezan a sentir o notar alguna aparicion o incremento de la enfermedad en sus mamas.

Hicimos una combinacion los datos de la edad de las mujeres del dataset, con los datos de la columna "Menopause" para ver la relacion con la edad y las mujeres que estan en transitando la menopausia del cancer de mamas. Atraves de uun grafico de torta.
"""

#Pie Chart, porcentajes de OverAll
df_overall = Cancer[['Age', 'Menopause']]
pie_overall = df_overall.groupby('Menopause').agg('count')
pie_overall = pie_overall.rename(columns={'Age': 'Frecuencia'})
pie_overall

axis = pie_overall.plot.pie(y='Frecuencia', autopct="%.1f%%", rot=0)
print(axis)
plt.show()

"""En este gafico se compara la edad y los datos de la menopausia con respecto de los datos del dataset, esto nos dice que existe uuna cierta rellacion entre estos datos, podemos ver que 52% aproximadamente de las mujeres no estan cursando este periodo, mientras que el 45% si son mujeres con menopausia y solo el 2% de ellas ya pasaron por este periodo.

Por ultimo, queria ver si existe la posibilidad o alguna relacion con la edad de las mujeres el dataset y el grado maligno de cancer en base a los datos del propio dataset.
"""

sns.boxplot(x="Deg-malig", y="Age", data=Cancer)

"""Existe una relacion entre ellos a mayor edad puede volverse mucho mas peligroso el cancer incrementaño su tamaño y el grado cancerigeno."""

import missingno as msno
p=msno.bar(Cancer)

"""# Importamos Segundo Dataset"""

Cancer2= pd.read_csv("/content/drive/MyDrive/breast-cancer.csv")
Cancer2.head()

from google.colab import drive
drive.mount('/content/drive')

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import f1_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression
import math

target = 'diagnosis'
labels = ['Benign','Malignant']
features = [i for i in Cancer2.columns.values if i not in [target]]
original_df = Cancer2.copy(deep=True)

Cancer2.drop(['id'],axis=1, inplace=True)

# Ahora el DataFrame no contiene la columna "id" lo cual limpia el análisis
print(Cancer2.columns)

Cancer2

# muestra el shape del dataset
print('Este data set tiene ' + str(Cancer2.shape[0]) + ' filas, y ' + str(Cancer2.shape[1]) + ' columnas')

"""# Conjunto de datos sobre el cancer de mama

# Informacion del Segundo Dataset
"""

Cancer2.duplicated()
duplicados =  Cancer2[Cancer2.duplicated()]
print(duplicados)

# transponemos la matriz anterior para visualizar mejor por variable.
Cancer2.describe().T

Cancer2.info()

print(Cancer2.columns)

Cancer2.isnull().sum()

"""# Analisis Exploratorio EDA"""

# Crea el countplot con las etiquetas en el eje x
ax = sns.countplot(x='diagnosis', data=Cancer2)

# Establece el título del gráfico
plt.title("Distribucion del Diagnostico")

# Agrega etiquetas para cada barra en el eje x
for p in ax.patches:
    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', fontsize=11, color='black', xytext=(0, 5),
                textcoords='offset points')

# Muestra el gráfico en pantalla
plt.show()

#Analicemos primero la distribución de la variable objetivo.

MAP={}
for e, i in enumerate(sorted(Cancer2[target].unique())):
     MAP[i]=labels[e]
#MAP={0:'Not-Survived',1:'Survived'}
df1 = Cancer2.copy()
df1[target]=df1[target].map(MAP)
explode=np.zeros(len(labels))
explode[-1]=0.1
print('\033[1mDistribución de la variable objetivo'.center(55))
plt.pie(df1[target].value_counts(), labels=df1[target].value_counts().index, counterclock=False, shadow=True,
         explode=explode, autopct='%1.1f%%', radius=1, startangle=0)
plt.show()

# Visualizamos el df a traves de Boxplot
plt.figure(figsize=(25, 8))
plt.xticks(rotation = 45, ha='right')
sns.boxplot(data=Cancer2)
plt.show()

plt.figure(figsize=(25, 8))
plt.xticks(rotation = 45, ha='right')
columns_to_plot = [col for col in Cancer2.columns if col not in ['area_mean', 'area_worst', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',
       'radius_se', 'smoothness_se',
       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',
       'fractal_dimension_se', 'smoothness_worst',
       'compactness_worst', 'concavity_worst', 'concave points_worst',
       'symmetry_worst', 'fractal_dimension_worst']]
sns.boxplot(data=Cancer2[columns_to_plot])
plt.show()

"""En este código, utilizamos una comprensión de lista para crear una lista llamada **columns_to_plot** que contiene todas las columnas excepto **'area_mean**' y **'area_worst**'. Luego, creamos el gráfico de boxplot utilizando solo estas columnas seleccionadas. Esto para poder analizar el df sin las columnas mencionadas ya que limitan el analisis de las demas columnas

A partir de los gráficos de boxplot de todas las columnas, podemos obtener varias conclusiones y comprender mejor la naturaleza de nuestros datos.

Los puntos fuera de los bigotes se consideran valores atípicos y pueden ser indicativos de valores inusuales o errores en los datos.

Al observar varios boxplots juntos, podemos hacer comparaciones entre las distribuciones de diferentes columnas y entender cómo se relacionan entre sí.
"""

#Regresion Lineal
sns.lmplot(x='area_mean',y='radius_worst',data=Cancer2,hue='diagnosis')

"""El gráfico de regresión lineal muestra la relación lineal entre **'id'** en el **eje x** y **'radius_worst**' en el **eje y**. Si la línea de regresión es inclinada hacia arriba, indica una **relación positiva** entre **'id' y 'radius_worst' (Caso de diagnosis Maligna)**. Si es inclinada hacia abajo, indica una relación negativa.
Si bien es casi equilibrada la relacion, se puede distinguir una leve pendiente hacia abajo.

Al mismo tiempo podemos ver que la dispersión de los puntos alrededor de la línea de regresión nos indica como se ajusta el modelo lineal a los datos. En este caso los registros no estan demasiado dispersos, por lo que se concluye que la relación es más lineal y se puede utilizar un modelo de regresión para predecir **'radius_worst'** en función de **'id'**.

El parámetro hue='diagnosis' agrega colores diferentes para cada valor único en la columna 'diagnosis'. Esto permite ver cómo se distribuyen los puntos en función del diagnóstico ('M' o 'B').

Por ultimo, se pueden identificar **valores atípicos** (outliers) hay puntos que se alejan significativamente de la línea de regresión.
"""

#Histograma de la columna perimeter_mean
sns.histplot(Cancer2.perimeter_mean,kde=True,color='b')

"""A partir de este gráfico, podemos obtener varias conclusiones sobre la distribución de los datos en la columna '**perimeter_mean**':

La posición del pico del histograma nos da una idea de la centralidad de la distribución. El pico representa el valor con mayor frecuencia en la columna.

La anchura del histograma nos indica la dispersión de los datos. En este caso, el histograma es estrecho, lo que significa que los valores están agrupados cerca del valor central, pero con una leve dispersion hacia los valores mas altos en la columna.
"""

#Histogramas de los datos del caancer de mama
data_maligno = Cancer2[Cancer2['diagnosis'] == 'M']['area_mean']
data_benigno = Cancer2[Cancer2['diagnosis'] == 'B']['area_mean']

color_maligno = '#CF5B47'
color_benigno = '#99F013'

plt.hist(data_maligno, bins=10, color=color_maligno, alpha=0.6, label='Maligno', density=True)
plt.hist(data_benigno, bins=10, color=color_benigno, alpha=0.6, label='Benigno', density=True)

plt.title("Histograma de area_mean")
plt.xlabel("area_mean")
plt.ylabel("Frecuencia")
plt.legend()

plt.show()

"""Realizamos un histograma comparativo de la columna '**area_mean**' para los casos malignos (diagnosis='M') y benignos (diagnosis='B') en el df. Cada histograma está coloreado de manera distinta para diferenciar los casos malignos y benignos, y ambos histogramas están normalizados para que la suma de las áreas de las barras sea igual a 1.

Podemos observar cómo se distribuyen los valores de '**area_mean**' para los casos malignos y benignos. La forma y la extensión de los histogramas nos dan una idea de cómo se concentran los valores alrededor de ciertos rangos de área para cada tipo de diagnóstico.

El gráfico permite una comparación visual rápida entre las distribuciones de '**area_mean**' para casos **malignos y benignos**. Podemos ver cómo se superponen las distribuciones de área para ambos diagnósticos. Esto sugiere que hay áreas con valores similares de '**area_mean**' entre los casos malignos y benignos. Esto nos indica que la característica '**area_mean**' no es suficiente por sí sola para distinguir claramente entre los diagnósticos.

Por ultimo, al estar normalizados a densidad, significa que podemos comparar visualmente las proporciones de los datos en lugar de conteos absolutos.
"""

#Matriz de Correlacion
df_encoded = Cancer2.copy()

label_encoder = LabelEncoder()
df_encoded['diagnosis'] = label_encoder.fit_transform(Cancer2['diagnosis'])

correlation = df_encoded.corr()

plt.figure(figsize=(26, 30))
sns.heatmap(correlation, annot=True)
plt.tight_layout()
plt.show()

# Excluir la columna 'id' de las características antes de calcular numericos
features_without_id = [col for col in features if col != 'id']
nu = Cancer2[features_without_id].nunique().sort_values()

nf = []
cf = []
nnf = 0
ncf = 0

for i in range(Cancer2[features_without_id].shape[1]):
    if nu.values[i] <= 7:
        cf.append(nu.index[i])
    else:
        nf.append(nu.index[i])

print('\n\033[1mInference:\033[0m El Dataset tiene {} columnas numericas y {} categoricas.'.format(len(nf), len(cf)))

#Visualizamos las columnas categoricas

print('\033[1mColumnas Categoricas:'.center(35))

n=3
plt.figure(figsize=[15,3*math.ceil(len(cf)/n)])

for i in range(len(cf)):
    if Cancer2[cf[i]].nunique()<=6:
        plt.subplot(math.ceil(len(cf)/n),n,i+1)
        sns.countplot(Cancer2[cf[i]])
    else:
        plt.subplot(3,1,i-1)
        sns.countplot(Cancer2[cf[i]])
plt.tight_layout()
plt.show()

"""Los datos tienen una distribucion normal de 30 columnas numericas y 0 categoricas aunque tambien hay muchos valores atípicos presentes en el conjunto de datos.
La visualización de las columnas categóricas revela mucha información sobre el conjunto de datos.
"""

#Visualizaremos como estan distruibidos los valores junto con los valores atipicos
nf = [i for i in features if i not in cf and i != 'id']

plt.figure(figsize=[15, 3 * math.ceil(len(features) / n)])
for c in range(len(nf)):
    plt.subplot(math.ceil(len(features) / n), n, c + 1)
    sns.histplot(Cancer2[nf[c]])
plt.show()

plt.figure(figsize=[15, 3 * math.ceil(len(features) / n)])
for c in range(len(nf)):
    plt.subplot(math.ceil(len(features) / n), n, c + 1)
    Cancer2.boxplot(nf[c])
plt.tight_layout()
plt.show()

"""# Pre Procesamiento de los Datos"""

#Removemos los registros duplicados (si los hay)

counter = 0
r,c = Cancer2.shape

df1 = Cancer2.copy()
df1.drop_duplicates(inplace=True)
df1.reset_index(drop=True,inplace=True)

if df1.shape==(r,c):
    print('\n\033[1mInferencia:\033[0m El Dataset no tiene ningun duplicado')
else:
    print(f'\n\033[1mInferencia:\033[0m Numeros de duplicados eliminados ---> {r-df1.shape[0]}')

"""Mediante estos codigos podemos que no hay valores duplicados pero si mediantes las graficas anteriores si hay muchos valores atípicos en el conjunto de datos. Intentemos imputar los valores faltantes."""

#Comprobamos si hay valores nulos

nvc = pd.DataFrame(df1.isnull().sum().sort_values(), columns=['Total Null Values'])
nvc['Percentage'] = round(nvc['Total Null Values']/df1.shape[0],3)*100
print(nvc)

#Convertimos los features categoricos en numericos

#df1 = df.copy()
ecc = nvc[nvc['Percentage']!=0].index.values
dcc = [i for i in Cancer2.columns if i not in ecc]

#Variable Objetivo
MAP={}
for i,e in enumerate(df1[target].unique()):
    MAP[e]=i
df1[target]=df1[target].map(MAP)
print('Variable Objetivo --->',MAP)

df3 = df1[dcc]
fcc = [i for i in cf if i not in ecc]

#Codificación binaria
oh=True
dm=True
for i in fcc:
    #print(i)
    if df3[i].nunique()==2:
        if oh==True: print("\033[1m\nOne-Codificacion Hot sobre columnas:\033[0m")
        print(i);oh=False
        df3[i]=pd.get_dummies(df3[i], drop_first=True, prefix=str(i))
    if (df3[i].nunique()>2 and df3[i].nunique()<17):
        if dm==True: print("\n\033[1mCodificacion Dummy sobre columnas:\033[0m")
        print(i);dm=False
        df3 = pd.concat([df3.drop([i], axis=1), pd.DataFrame(pd.get_dummies(df3[i], drop_first=True, prefix=str(i)))],axis=1)

df3.shape

#Removemos los outliers

df4 = df3.copy()

for i in [i for i in df4.columns]:
    if df4[i].nunique()>=12:
        Q1 = df4[i].quantile(0.15)
        Q3 = df4[i].quantile(0.85)
        IQR = Q3 - Q1
        df4 = df4[df4[i] <= (Q3+(1.5*IQR))]
        df4 = df4[df4[i] >= (Q1-(1.5*IQR))]
df4 = df4.reset_index(drop=True)
display(df4.head())
print('\n\033[1mInferencia:\033[0m Antes de eliminar los outliers, el dataset tenia {} registros.'.format(df1.shape[0]))
print('\033[1mInferencia:\033[0m Posterior a eliminar los outliers, el dataset tiene {} registros.'.format(df4.shape[0]))

#Corrección del desequilibrio mediante la técnica SMOTE. (Muestreo de datos)
from imblearn.over_sampling import SMOTE
df5 = df4.copy()

print('Original class distribution:')
print(df5[target].value_counts())

xf = df5.columns
X = df5.drop([target],axis=1)
Y = df5[target]

smote = SMOTE()
X, Y = smote.fit_resample(X, Y)

df5 = pd.DataFrame(X, columns=xf)
df5[target] = Y

print('\nClass distribution after applying SMOTE Technique:',)
print(Y.value_counts())

#Tamaño final del conjunto de datos después de realizar el preprocesamiento

df = df5.copy()
plt.title('Final Dataset Samples')
plt.pie([df.shape[0], original_df.shape[0]-df4.shape[0], df5.shape[0]-df4.shape[0]], radius = 1, shadow=True,
        labels=['Datos retenidos','Datos eliminados','Datos sumados'], counterclock=False, autopct='%1.1f%%', pctdistance=0.9, explode=[0,0,0])
plt.pie([df.shape[0]], labels=['100%'], labeldistance=-0, radius=0.78, shadow=True, colors=['powderblue'])
plt.show()

print('\n\033[1mInferencia:\033[0mEl dataset final luego del preprocesamiento tiene {} registros & {} columnas.'.format(df.shape[0], df.shape[1]))

"""Mediante estos codigos pudimos verificar si hay valores nulos dentro del dataset, convertis valores categoricos en numericos, removimos los outliers, despues corregimos el desequilibrio de los datos en base a un muestreo de datos (Smote).
Despues mediiante una grafica de torta podemos ver como quedaron esos dattos despues de procesamiento de datos.

# **Manipulacion de Datos**
"""

#Dividir los datos en conjuntos de entrenamiento y prueba.

df = df5.copy()

X = df.drop([target],axis=1)
Y = df[target]
Train_X, Test_X, Train_Y, Test_Y = train_test_split(X, Y, train_size=0.8, test_size=0.2, random_state=0)

print('Original ---> ',X.shape,Y.shape,'\nTraining ---> ',Train_X.shape,Train_Y.shape,'\nTesting ---> ', Test_X.shape,'', Test_Y.shape)

#Escalado de Features (estandarización)

std = StandardScaler()

print('\033[1mEstandarizacion sobre Training'.center(100))
Train_X_std = std.fit_transform(Train_X)
Train_X_std = pd.DataFrame(Train_X_std, columns=X.columns)
display(Train_X_std.describe())

print('\n','\033[1mEstandarizacion sobre Testing'.center(100))
Test_X_std = std.transform(Test_X)
Test_X_std = pd.DataFrame(Test_X_std, columns=X.columns)
display(Test_X_std.describe())

"""# Feature Selection/Extraccion"""

sns.set_theme(style="white")

plt.figure(figsize=(20, 15))
mask = np.triu(np.ones_like(Cancer2.select_dtypes(include="number").corr(), dtype=bool))
ax = sns.heatmap(Cancer2.select_dtypes(include="number").corr(), annot=True, cmap='coolwarm', fmt='.2f',
            linewidths=1, linecolor='white', mask=mask, center=0, cbar_kws={"shrink": .5})

for label in ax.get_yticklabels():
    label.set_size(15)

for label in ax.get_xticklabels():
    label.set_size(15)

plt.tight_layout()
plt.show()

"""La correlación entre las variables transmite mucha información sobre la relación entre ellas. Mediante esta correlacion podemos ver una **fuerte multicolinealidad en el conjunto de datos**.

Utilizaremos diferentes técnicas para ver si podemos mejorar el rendimiento del modelo realizando pasos de Selección/Extracción de Features para cuidar esta multicolinealidad.
"""

#Aplicamos las Transformaciones PCA

#scores1.append(f1_score(Test_Y,LogisticRegression().fit(Train_X_std, Train_Y).predict(Test_X_std),average='weighted')*100)
#scores2.append(f1_score(Test_Y,RandomForestClassifier().fit(Train_X_std, Train_Y).predict(Test_X_std),average='weighted')*100)
#scores3.append(f1_score(Test_Y,XGBClassifier().fit(Train_X_std, Train_Y, eval_metric='logloss').predict(Test_X_std),average='weighted')*100)
from tqdm import tqdm
scores1=[]; scores2=[]; scores3=[]
for i in tqdm(range(len(X.columns.values))):
    pca = PCA(n_components=Train_X_std.shape[1]-i)
    Train_X_std_pca = pca.fit_transform(Train_X_std)
    #print('The shape of final transformed training feature set:')
    #print(Train_X_std_pca.shape)
    Train_X_std_pca = pd.DataFrame(Train_X_std_pca)

    Test_X_std_pca = pca.transform(Test_X_std)
    #print('\nThe shape of final transformed testing feature set:')
    #print(Test_X_std_pca.shape)
    Test_X_std_pca = pd.DataFrame(Test_X_std_pca)

    scores1.append(f1_score(Test_Y,LogisticRegression().fit(Train_X_std_pca, Train_Y).predict(Test_X_std_pca),average='weighted')*100)
    scores2.append(f1_score(Test_Y,RandomForestClassifier().fit(Train_X_std_pca, Train_Y).predict(Test_X_std_pca),average='weighted')*100)
    scores3.append(f1_score(Test_Y,XGBClassifier().fit(Train_X_std_pca, Train_Y, eval_metric='logloss').predict(Test_X_std_pca),average='weighted')*100)


plt.plot(scores1, label='LR')
plt.plot(scores2, label='RF')
plt.plot(scores3, label='XG')
#plt.ylim([0.80,0.84])
plt.legend()
plt.grid()
plt.show()

"""**PCA**: Notamos mejores puntuaciones al eliminar algunas características multicolineales. Pero para evitar la dimensionalidad, podemos capturar el 90% superior de la varianza de datos explicada por los n principales componentes de PCA

# **Modelo Predictivo/ML**

# Logistic Regression (LR)
"""

# Creando analisis de LR
from scipy.stats import loguniform
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_curve, auc

def AUC_ROC_plot(Test_Y, pred_prob):
    fpr, tpr, _ = roc_curve(Test_Y, pred_prob)
    roc_auc = auc(fpr, tpr)

    plt.figure()
    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('Tasa de falsos positivos')
    plt.ylabel('Tasa de verdaderos positivos')
    plt.title('Característica Operativa del Receptor')
    plt.legend(loc='lower right')
    plt.show()

def Classification_Summary(pred, pred_prob, i):
    Evaluation_Results.loc['LR', 'Accuracy'] = round(accuracy_score(Test_Y, pred), 3) * 100
    Evaluation_Results.loc['LR', 'Precision'] = round(precision_score(Test_Y, pred, average='weighted'), 3) * 100
    Evaluation_Results.loc['LR', 'Recall'] = round(recall_score(Test_Y, pred, average='weighted'), 3) * 100
    Evaluation_Results.loc['LR', 'F1-score'] = round(f1_score(Test_Y, pred, average='weighted'), 3) * 100
    Evaluation_Results.loc['LR', 'AUC-ROC score'] = round(roc_auc_score(Test_Y, pred_prob[:, 1]), 3) * 100
    print('{}{}\033[1m Evaluating {} \033[0m{}{}\n'.format('<'*3, '-'*35, 'LR', '-'*35, '>'*3))
    print('Accuracy = {}%'.format(round(accuracy_score(Test_Y, pred), 3) * 100))
    print('F1 Score = {}%'.format(round(f1_score(Test_Y, pred, average='weighted'), 3) * 100))
    print('\n \033[1mConfusion Matrix:\033[0m\n', confusion_matrix(Test_Y, pred))
    print('\n\033[1mClassification Report:\033[0m\n', classification_report(Test_Y, pred))

    AUC_ROC_plot(Test_Y, pred_prob[:, 1])

# Definir datos de entrenamiento y prueba (Train_X_std, Train_Y, Test_X_std, Test_Y) aquí

# Armamos la clasificaciion de regresion lineal
LR_model = LogisticRegression()

space = dict()
space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']
space['penalty'] = ['l2']  # 'none', 'l1', 'l2', 'elasticnet'
space['C'] = loguniform(1e-5, 100)

cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)

RCV = RandomizedSearchCV(LR_model, space, n_iter=50, scoring='roc_auc', n_jobs=-1, cv=5, random_state=1)

LR = RCV.fit(Train_X_std, Train_Y).best_estimator_
pred = LR.predict(Test_X_std)
pred_prob = LR.predict_proba(Test_X_std)

# Crear un DataFrame para los resultados de evaluación
Evaluation_Results = pd.DataFrame(index=['LR'])

# Llama a la función de resumen de clasificación
Classification_Summary(pred, pred_prob, 0)

print('\n\033[1mInterpreting the Output of Logistic Regression:\n\033[0m')
print('intercept ', LR.intercept_[0])
print('classes', LR.classes_)
display(pd.DataFrame({'coeff': LR.coef_[0]}, index=Train_X_std.columns))

from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit(Train_X, Train_Y)

regressor.coef_

regressor.intercept_

coeff_df = pd.DataFrame(regressor.coef_, X.columns, columns=['Coefficient'])
coeff_df

#Realizando las predicciones
y_pred = regressor.predict(Test_X)

"""Para comparar los valores de salida reales X_test con los valores predichos, convertimos en df:"""

df = pd.DataFrame({'Actual': Test_Y, 'Predicted': y_pred})
df

from sklearn.metrics import r2_score
r2_score(Test_Y,y_pred)

"""En cambio en este segundo algoritmo podemos observar que el rendimiento es **relativamente bueno**, con un **Accuracy = 97%**
en la matriz de confusion podemos ver que solamente tiene 3 errores aproximadamente  del total de datos separados para el entrenamiento del algoritmo.

# **Random Forest Classfier**
"""

RF_model = RandomForestClassifier()

param_dist={'bootstrap': [True, False],
            'max_depth': [10, 20, 50, 100, None],
            'max_features': ['auto', 'sqrt'],
            'min_samples_leaf': [1, 2, 4],
            'min_samples_split': [2, 5, 10],
            'n_estimators': [50, 100]}

cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)

RCV = RandomizedSearchCV(RF_model, param_dist, n_iter=50, scoring='roc_auc', n_jobs=-1, cv=5, random_state=1)

RF = RCV.fit(Train_X_std, Train_Y).best_estimator_
pred = RF.predict(Test_X_std)
pred_prob = RF.predict_proba(Test_X_std)
Classification_Summary(pred,pred_prob,2)

print('\n\033[1mInterpretamos los resultados de Random Forest:\n\033[0m')
rfi=pd.Series(RF.feature_importances_, index=Train_X_std.columns).sort_values(ascending=False)
plt.barh(rfi.index,rfi.values)
plt.show()

from sklearn.ensemble import RandomForestClassifier
random = RandomForestClassifier()
random.fit(Train_X, Train_Y)

#Realizando las predicciones
y_pred = random.predict(Test_X)

df2 = pd.DataFrame({'Actual': Test_Y, 'Predicted': y_pred})
df2

"""En cambio en este segundo algoritmo podemos observar que el rendimiento es **bueno**, con un **Accuracy = 94%**
en la matriz de confusion podemos ver que solamente tiene 6 errores aproximadamente  del total de datos separados para el entrenamiento del algoritmo.

# Maquina de Vectores de Valores
"""

# Creando analisis de Support Vector Machine
from sklearn.svm import SVC
SVM_model = SVC(probability=True).fit(Train_X_std, Train_Y)

svm_param = {"C": [.01, .1, 1, 5, 10, 100],
             "gamma": [.01, .1, 1, 5, 10, 100],
             "kernel": ["rbf"],
             "random_state": [1]}

cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)

RCV = RandomizedSearchCV(SVM_model, svm_param, n_iter=50, scoring='roc_auc', n_jobs=-1, cv=5, random_state=1)

SVM = RCV.fit(Train_X_std, Train_Y).best_estimator_
pred = SVM.predict(Test_X_std)
pred_prob = SVM.predict_proba(Test_X_std)
Classification_Summary(pred,pred_prob,4)

from sklearn import svm
MV = svm.SVC()
MV.fit(Train_X, Train_Y)

#Realizando las predicciones
y_pred = MV.predict(Test_X)

df3 = pd.DataFrame({'Actual': Test_Y, 'Predicted': y_pred})
df3

"""En cambio en este segundo algoritmo podemos observar que el rendimiento es **relativamente bueno**, con un **Accuracy = 97%**
en la matriz de confusion podemos ver que solamente tiene 3 errores aproximadamente  del total de datos separados para el entrenamiento del algoritmo.

# **Gradient Boosting**
"""

# Creando analisis de Gradient Boosting
from sklearn.ensemble import GradientBoostingClassifier
GB_model = GradientBoostingClassifier().fit(Train_X_std, Train_Y)
param_dist = {
    "n_estimators":[5,20,100,500],
    "max_depth":[1,3,5,7,9],
    "learning_rate":[0.01,0.1,1,10,100]
}

cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)

RCV = RandomizedSearchCV(GB_model, param_dist, n_iter=50, scoring='roc_auc', n_jobs=-1, cv=5, random_state=1)

GB = RCV.fit(Train_X_std, Train_Y).best_estimator_
pred = GB.predict(Test_X_std)
pred_prob = GB.predict_proba(Test_X_std)
Classification_Summary(pred,pred_prob,6)

from sklearn.ensemble import GradientBoostingClassifier
modelo_gb = GradientBoostingClassifier()
modelo_gb.fit(Train_X, Train_Y)

#Realizando las predicciones
y_pred = modelo_gb.predict(Test_X)

df2 = pd.DataFrame({'Actual': Test_Y, 'Predicted': y_pred})
df2

"""En cambio en este segundo algoritmo podemos observar que el rendimiento es **relativamente bueno**, con un **Accuracy = 97%**
en la matriz de confusion podemos ver que solamente tiene 3 errores aproximadamente  del total de datos separados para el entrenamiento del algoritmo.

# **Conclusiones & Insights**

Insights: para resolver el planteamiento del problema actual, es más importante centrarse en la puntuación de Recall. Podemos observar que el modelo SVM, LR y Gradient Boosting funcionaron mejor en el conjunto de datos actual.

Éstos son algunos de las conclusiones clave del proyecto:

1.  El conjunto de datos tenia un total 569 muestras y después del preprocesamiento, se eliminaron el 7,3% de las muestras de datos.
2.  Las muestras estaban ligeramente desequilibradas después del procesamiento, por lo que se aplicó la técnica SMOTE a los datos para equilibrar las clases, agregando un 18,8 % más de muestras al conjunto de datos.
3.  Visualizar la distribución de datos y sus relaciones nos ayudó a obtener algunas ideas sobre la relación entre el conjunto de características.
4.  Se llevó a cabo la selección/eliminación de funciones y se preseleccionaron las funciones apropiadas.
5.  Probar múltiples algoritmos con hiperparámetros de ajuste nos brindó cierta comprensión sobre el rendimiento del modelo para varios algoritmos en este conjunto de datos específico.
6.  Maquina de Vectores (SVM) y el Gradient Boosting tuvieron un desempeño excepcionalmente bueno en el conjunto de datos actual, considerando Recall Score como la métrica clave.
7. Sin embargo, se podria considerar también un modelo más simple como la regresión logística, ya que es más generalizable.

En base a todos los datos de los datasets y a raiz de algunos modelos realizados consideramos que es posible crear una manera de predecir los diagnósticos del cáncer de mama y su importancia en la detección temprana y el tratamiento efectivo.
Lograr impactar con la predicción precisa del cáncer de mama en la supervivencia y calidad de vida de los pacientes.

Argentina es uno de los paises donde mas se producen las muertes por **cancer de mama** mas son las que estan en el **interior del pais**, donde la mayoria de esas mujeres tienen bajos recursos economicos para poder asistir a una consulta medica o poder recibir/continuar con algun tipo de tratamiento.

-Como profesionales dentro del ambito de salud consideramos que se deberia viralizar mas la campaña de concientizacion del cancer de mama no solo por los medios de comunicion ya que en la mayoria de estas provincias no lo consumen diariamente y **seguir consientizando la importancia de los controles medicos, ofreciendo la realizacion de mamografias gratuitas sin cobertura medica en los hospitales publicos una o dos veces en la semana.**

-Consideramos que con el objetivo de acercarse al público general en **Octube "Mes Rosa" **se podrian dejar folletos en los hospitales para que los mismo medicos incentiven a sus pacientes a realizarse los estudios y generarles cierta confianza para que se realicen esos chequeos.
Tambien se podria visibilizar la campaña contra el cancer de mama **en los shopping** de esta manera se invitaran a las personas a sumarse a la campaña, por la cual se le brindara informacion, se entregaran lazos rosas y para quien quiera participar tendra la posiibilidad de fotografiarse en el stand no solo para mostrar en redes sociales, sino para fomentar y ayudar a mas mujeres atraves del mensaje de boca en boca lo riesgoso que es y como podrian preveneirlo.

-Consideramos que como cualquier tipo de cancer mortal es necesario hacer mas visible esta enfermedad ya que en muchos casos en un estadio temprano no tienen sintomas y suele ser hereditario.
"""